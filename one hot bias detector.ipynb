{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edri-avichai/Practical-Deep-Learning-Workshop-Assignment-4/blob/main/one%20hot%20bias%20detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:39.456540700Z",
          "start_time": "2023-10-17T14:16:38.558740500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "ad48f83f-fde8-4955-ddb4-4f13034b72dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n",
            "Collecting shap\n",
            "  Downloading shap-0.43.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.43.0 slicer-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install shap\n",
        "import pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tabulate import tabulate\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from catboost import CatBoostClassifier\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "categorical_threshold = 10\n",
        "tpr_threshold = 0.6 # small tpr is bad\n",
        "fpr_threshold = 0.4 # small fpr is good\n",
        "sample_is_bias_threshold = 1 # minimum number of features that are biased in a sample\n",
        "odds_difference_threshold = 0.02 # small odds difference is good\n",
        "google_colab = True"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:39.477484900Z",
          "start_time": "2023-10-17T14:16:38.576763700Z"
        },
        "id": "efa49dfe969209b0"
      },
      "id": "efa49dfe969209b0"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "def get_categorical_features(dataset, threshold ):\n",
        "    return [col for col in dataset.columns if dataset[col].dtype == 'object' or dataset[col].nunique() <= threshold]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:39.478483300Z",
          "start_time": "2023-10-17T14:16:38.678898Z"
        },
        "id": "97bc9f084d75c26d"
      },
      "id": "97bc9f084d75c26d"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "def one_hot_encode_categorical_features(dataset, categorical_features, dataset_name):\n",
        "\n",
        "    # Create a copy of the original dataset to avoid modifying the input dataset\n",
        "    encoded_dataset = dataset.copy()\n",
        "    new_columns = []\n",
        "\n",
        "    # Iterate through each categorical feature and apply one-hot encoding\n",
        "    for feature in categorical_features:\n",
        "        # Handle NULL values by filling them with a unique category label (e.g., 'NULL')\n",
        "        encoded_dataset[feature] = encoded_dataset[feature].fillna('NULL')\n",
        "\n",
        "        # Perform one-hot encoding using Pandas' get_dummies function\n",
        "        encoded_feature = pd.get_dummies(encoded_dataset[feature], prefix=feature)\n",
        "        new_columns.extend(encoded_feature.columns)\n",
        "\n",
        "        # Concatenate the one-hot encoded feature back to the dataset and drop the original feature\n",
        "        encoded_dataset = pd.concat([encoded_dataset, encoded_feature], axis=1)\n",
        "        encoded_dataset.drop(columns=[feature], inplace=True)\n",
        "    #save onehot dats_set\n",
        "    encoded_dataset.to_csv(f\"one_hot_{dataset_name}.csv\", index=False)\n",
        "    return encoded_dataset, new_columns"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:39.479479600Z",
          "start_time": "2023-10-17T14:16:38.712922600Z"
        },
        "id": "eac2f8ff6e1cc7b1"
      },
      "id": "eac2f8ff6e1cc7b1"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if not google_colab:\n",
        "  adult_base = pd.read_csv(\"D:\\master\\datasets\\\\adult.csv\")\n",
        "  compass_base = pd.read_csv('D:\\master\\datasets\\compas-scores-two-years_v1.csv')\n",
        "  law_base = pd.read_csv('D:\\master\\datasets\\\\law_school.csv')\n",
        "  # german_base = pd.read_csv('D:\\master\\datasets\\\\german.csv')\n",
        "  # wids_base = pd.read_csv('D:\\master\\datasets\\\\wids.csv')\n",
        "  diabetes_base = pd.read_csv('D:\\master\\datasets\\\\diabetes-clean.csv')\n",
        "else:\n",
        "  from google.colab import drive\n",
        "\n",
        "  # This will prompt for authorization.\n",
        "  drive.mount('/content/drive')\n",
        "  adult_base = pd.read_csv(\"/content/drive/MyDrive/master/datasets/adult.csv\")\n",
        "  compass_base = pd.read_csv('/content/drive/MyDrive/master/datasets/compas-scores-two-years_v1.csv')\n",
        "  law_base = pd.read_csv('/content/drive/MyDrive/master/datasets/law_school.csv')\n",
        "  # german_base = pd.read_csv('D:\\master\\datasets\\\\german.csv')\n",
        "  # wids_base = pd.read_csv('D:\\master\\datasets\\\\wids.csv')\n",
        "  diabetes_base = pd.read_csv('/content/drive/MyDrive/master/datasets/diabetes-clean.csv')\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:41.586323300Z",
          "start_time": "2023-10-17T14:16:38.757383500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b74872487a7cb0fd",
        "outputId": "f4521475-0b29-4d91-a49f-82bdcc7be039"
      },
      "id": "b74872487a7cb0fd"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "compass_base = compass_base[['age', 'c_charge_degree', 'race', 'age_cat', 'score_text', 'sex', 'priors_count',\n",
        "               'days_b_screening_arrest', 'decile_score', 'two_year_recid']]\n",
        "compass_base = compass_base[((compass_base['days_b_screening_arrest'] <= 30) &\n",
        "                             (compass_base['days_b_screening_arrest'] >= -30) &\n",
        "                             # (compass['is_recid'] != -1) &\n",
        "                             (compass_base['c_charge_degree'] != 'O') &\n",
        "                             (compass_base['score_text'] != 'N/A')\n",
        "                             )]\n",
        "# compass_cat =[ 'sex','age_cat', 'race', 'c_charge_degree', 'score_text']\n",
        "compass_cat = get_categorical_features(compass_base, categorical_threshold)\n",
        "compass_target = 'two_year_recid'\n",
        "compass_cat.remove(compass_target)\n",
        "compass,compass_one_hot_col = one_hot_encode_categorical_features(compass_base, compass_cat, \"compass\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:41.587320200Z",
          "start_time": "2023-10-17T14:16:41.250445900Z"
        },
        "id": "bd190c46ccae927b"
      },
      "id": "bd190c46ccae927b"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "adult  = adult_base[['age', 'fnlwgt', 'education', 'education.num',\n",
        "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country','income']]\n",
        "adult_target = 'income'\n",
        "adult_cat = get_categorical_features(adult, categorical_threshold)\n",
        "adult_cat.remove(adult_target)\n",
        "adult[adult_target] = adult[adult_target].apply(lambda x: 0 if x == '<=50K' else 1)\n",
        "adult,adult_one_hot_col = one_hot_encode_categorical_features(adult, adult_cat, \"adult\")\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:43.625474300Z",
          "start_time": "2023-10-17T14:16:41.499481500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0d78119b8523083",
        "outputId": "375274f5-b805-43e5-b175-410c28d5af75"
      },
      "id": "e0d78119b8523083"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0    18505\n",
            "0.0     2293\n",
            "Name: pass_bar, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "law_target = 'pass_bar'\n",
        "law_cat = get_categorical_features(law_base, categorical_threshold)\n",
        "law_cat.remove(law_target)\n",
        "law,law_one_hot_col = one_hot_encode_categorical_features(law_base, law_cat, \"law\")\n",
        "print(law[law_target].value_counts())"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:16:44.173520800Z",
          "start_time": "2023-10-17T14:16:43.585581100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d2d91b481012df8",
        "outputId": "d12dacf3-412c-43e4-9670-c80ffd19fb88"
      },
      "id": "4d2d91b481012df8"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "diabetes_target = 'readmitted'\n",
        "diabetes_cat = get_categorical_features(diabetes_base, categorical_threshold)\n",
        "diabetes_cat.remove(diabetes_target)\n",
        "diabetes,diabetes_one_hot_col = one_hot_encode_categorical_features(diabetes_base, diabetes_cat, \"diabetes\")\n",
        "diabetes[diabetes_target] = diabetes[diabetes_target].apply(lambda x: 0 if x == '<30' else 1)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:58.510945100Z",
          "start_time": "2023-10-17T14:16:44.177510Z"
        },
        "id": "6087f77d82212fa5"
      },
      "id": "6087f77d82212fa5"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "def one_csv_of_values_count_in_dataset(dataset, dataset_name):\n",
        "    dataset_value_count = pd.DataFrame(columns=['feature', '0', '1'])\n",
        "    for col in dataset.columns:\n",
        "        value_counts = dataset[col].value_counts()\n",
        "        count_0 = value_counts[0] if 0 in value_counts.index else 0\n",
        "        count_1 = value_counts[1] if 1 in value_counts.index else 0\n",
        "        row_data = {'feature': col, '0': count_0, '1': count_1}\n",
        "        dataset_value_count = pd.concat([dataset_value_count, pd.DataFrame([row_data])], ignore_index=True)\n",
        "    dataset_value_count.to_csv(f\"values_count_{dataset_name}.csv\", index=False)\n",
        "one_csv_of_values_count_in_dataset(compass, \"compass\")\n",
        "one_csv_of_values_count_in_dataset(adult, \"adult\")\n",
        ""
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.573870400Z",
          "start_time": "2023-10-17T14:17:58.420158Z"
        },
        "id": "5b07ce30ab9d6b5e"
      },
      "id": "5b07ce30ab9d6b5e"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": [
        "def print_metrics(y_gt, y_pred):\n",
        "    cm = confusion_matrix(y_gt, y_pred)\n",
        "    if cm.shape !=(2,2):\n",
        "        return None\n",
        "    if cm.shape == (1, 1):\n",
        "        if 1 == y_gt.iloc[0] and 1 == y_pred.iloc[0]:\n",
        "            tn, fp, fn, tp = 0, 0, 0, 1\n",
        "        else:\n",
        "            tn, fp, fn, tp = 1, 0, 0, 0\n",
        "    else:\n",
        "        tn, fp, fn, tp = confusion_matrix(y_gt, y_pred).ravel()\n",
        "    accuracy = (tp+tn)/(tp+tn+fn+fp)\n",
        "    # precision = tp/(tp+fp)\n",
        "    if tp + fp == 0:\n",
        "        precision = 0  # Handle the case where denominator is zero\n",
        "    else:\n",
        "        precision = tp / (tp + fp)\n",
        "    # recall = tp/(tp+fn)\n",
        "    if tp + fn == 0:\n",
        "        recall = 0  # Handle the case where denominator is zero\n",
        "    else:\n",
        "        recall = tp / (tp + fp)\n",
        "    if fp+tn == 0:\n",
        "        fpr = 0  # Handle the case where denominator is zero\n",
        "    else:\n",
        "        fpr = fp/(fp+tn)\n",
        "\n",
        "    if tp + fn == 0:\n",
        "        tpr = 0  # Handle the case where denominator is zero\n",
        "    else:\n",
        "        tpr = tp /(tp + fn)\n",
        "\n",
        "\n",
        "    fn_fp = fn+fp\n",
        "\n",
        "    # print('conf matrix:\\n', confusion_matrix(y_gt, y_pred))\n",
        "    metrics_table = [ [\"TN\",\" FP\", \"FN\",\"TP\",\"Accuracy\"],\n",
        "        [ tn, fp, fn, tp, accuracy],\n",
        "        [\"Precision\",\"Recall\", \"False Positive Rate (FPR)\",\"True Positive Rate (TPR)\",\"Sum of FN and FP\"],\n",
        "        [ precision, recall, fpr, tpr, fn_fp]]\n",
        "\n",
        "    # Print the metrics table\n",
        "    # print(tabulate(metrics_table, tablefmt=\"grid\"))\n",
        "\n",
        "    #returm fpr, tpr, accuracy\n",
        "    return {\"fpr\": fpr,\"tpr\": tpr, \"accuracy\": accuracy}\n",
        "\n",
        "# bias metric - equal opportunity difference\n",
        "def opportunity_diff_tpr(tpr1, tpr2):\n",
        "    return abs(tpr1-tpr2)\n",
        "\n",
        "# bias metric - equal opportunity difference\n",
        "def opportunity_diff_fpr(fpr1, fpr2):\n",
        "    return abs(fpr1-fpr2)\n",
        "\n",
        "# bias metric - average absolute odds difference\n",
        "def odds_diff(tpr1, tpr2, fpr1, fpr2):\n",
        "    return 0.5*(abs(tpr2-tpr1) + abs(fpr2-fpr1))\n",
        "\n",
        "# bias metric - statistical parity difference\n",
        "def parity_diff(y_pred_0, y_pred_1):\n",
        "    return abs(len(y_pred_0)/(len(y_pred_0)+len(y_pred_1)) - len(y_pred_1)/(len(y_pred_1)+len(y_pred_0)))\n",
        "\n",
        "\n",
        "    # bias metric - Disparate impact\n",
        "def disparate_impact(y_pred_0, y_pred_1):\n",
        "    if len(y_pred_0) == 0 or len(y_pred_1) == 0:\n",
        "        return 0\n",
        "\n",
        "    return min((len(y_pred_0)/len(y_pred_0 + y_pred_1)) / (len(y_pred_1)/len(y_pred_1+len(y_pred_0)))\n",
        "    ,(len(y_pred_1)/len(y_pred_0+y_pred_1)) / (len(y_pred_0)/len(y_pred_1+len(y_pred_0))))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.576864200Z",
          "start_time": "2023-10-17T14:17:59.093955300Z"
        },
        "id": "e7d36f7ba28330d8"
      },
      "id": "e7d36f7ba28330d8"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "def bias_in_single_column(dataset, column_name, target):\n",
        "    # print('bias in column: ', column_name)\n",
        "    one_value = dataset[dataset[column_name] == 1]\n",
        "    zero_value = dataset[dataset[column_name] == 0]\n",
        "\n",
        "    one_metrics = print_metrics(one_value[target], one_value['y_pred'])\n",
        "    if one_metrics is None:\n",
        "        return None\n",
        "    zero_metrics = print_metrics(zero_value[target], zero_value['y_pred'])\n",
        "    if zero_metrics is None:\n",
        "        return None\n",
        "    one_value_majority = one_value[target].value_counts().idxmax()\n",
        "    zero_value_majority = zero_value[target].value_counts().idxmax()\n",
        "    o_d_t = opportunity_diff_tpr(one_metrics['tpr'], zero_metrics['tpr'])\n",
        "    o_d_f = opportunity_diff_fpr(one_metrics['fpr'], zero_metrics['fpr'])\n",
        "    o_d = odds_diff(one_metrics['tpr'], zero_metrics['tpr'], one_metrics['fpr'], zero_metrics['fpr'])\n",
        "    p_d = parity_diff(one_value['y_pred'], zero_value['y_pred'])\n",
        "    # d_i = disparate_impact(one_value['y_pred'], zero_value['y_pred'])\n",
        "\n",
        "    if o_d > odds_difference_threshold:\n",
        "        bias_dict = {'equal opportunity for tpr: (close 0)': o_d_t,\n",
        "                      'equal opportunity for fpr: (close 0)': o_d_f,\n",
        "                      'odds difference: (close 0)': o_d,\n",
        "                      'statistical parity difference: (close 0)': p_d,\n",
        "                      # 'disparate impact: (close 1)': disparate_impact_\n",
        "                      f'tpr for 1': one_metrics[\"tpr\"],\n",
        "                    f'fpr for 1': one_metrics[\"fpr\"],\n",
        "                    f'tpr for 0': zero_metrics[\"tpr\"],\n",
        "                    f'fpr for 0 ': zero_metrics[\"fpr\"],\n",
        "                     f'majority in 1': one_value_majority,\n",
        "                     f'majority in 0': zero_value_majority,\n",
        "                      }\n",
        "        if one_metrics['tpr'] < tpr_threshold:\n",
        "                bias_dict[\"privilege in one\"] = False\n",
        "        else:\n",
        "                bias_dict[\"privilege in one\"] = True\n",
        "        if zero_metrics['tpr'] < tpr_threshold:\n",
        "                bias_dict[\"privilege in zero\"] = False\n",
        "        else:\n",
        "                bias_dict[\"privilege in zero\"] = True\n",
        "        # pprint.pprint(bias_dict)\n",
        "\n",
        "\n",
        "        return bias_dict\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.576864200Z",
          "start_time": "2023-10-17T14:17:59.189902200Z"
        },
        "id": "fa4dcf798df4e992"
      },
      "id": "fa4dcf798df4e992"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [],
      "source": [
        "def bias_in_dataset(train_set, target ,categorical_features):\n",
        "    bias_dict = {}\n",
        "    train, val = train_test_split(train_set, test_size=0.25, random_state=42,stratify=train_set[target])\n",
        "    model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=5, loss_function='Logloss', verbose= False)\n",
        "    model.fit(train.drop(columns=[target]), train[target], cat_features=categorical_features)\n",
        "    val['y_pred'] = model.predict(val.drop(columns=[target]))\n",
        "    print(accuracy_score(val['y_pred'],val[target]))\n",
        "    for col in categorical_features:\n",
        "\n",
        "        col_bias = bias_in_single_column(val, col, target)\n",
        "        if col_bias is not None:\n",
        "            bias_dict[col] = col_bias\n",
        "    return bias_dict\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.576864200Z",
          "start_time": "2023-10-17T14:17:59.213922700Z"
        },
        "id": "3aecb0a21f2ec050"
      },
      "id": "3aecb0a21f2ec050"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "def bias_features_using_shap(train_set, target ,categorical_features):\n",
        "    train, val = train_test_split(train_set, test_size=0.25, random_state=42,stratify=train_set[target])\n",
        "    model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=5, loss_function='Logloss', verbose=True)\n",
        "    model.fit(train.drop(columns=[target]), train[target], cat_features=categorical_features)\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer(train.drop(columns=[target]), train[target])\n",
        "    shap.summary_plot(shap_values, train.drop(columns=[target]))\n",
        "    shap.summary_plot(shap_values, train.drop(columns=[target]), plot_type=\"bar\")\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.577861400Z",
          "start_time": "2023-10-17T14:17:59.257878800Z"
        },
        "id": "d164ef08d3ec2d01"
      },
      "id": "d164ef08d3ec2d01"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "source": [
        "def import_csv_summary(bias_dict, dataset_name):\n",
        "    bias_summary = []\n",
        "    columns = [\"dataset\", \"feature\"]\n",
        "    columns.extend(list(bias_dict[list(bias_dict.keys())[0]].keys()))\n",
        "    for feature in bias_dict.keys():\n",
        "        bias_summary.append([dataset_name, feature])\n",
        "        for metric in bias_dict[feature].keys():\n",
        "            bias_summary[-1].append(bias_dict[feature][metric])\n",
        "    bias_summary = pd.DataFrame(bias_summary, columns=columns)\n",
        "    bias_summary.to_csv(f\"bias_summary_{dataset_name}.csv\", index=False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.577861400Z",
          "start_time": "2023-10-17T14:17:59.282889400Z"
        },
        "id": "cd85b831a9193e53"
      },
      "id": "cd85b831a9193e53"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.577861400Z",
          "start_time": "2023-10-17T14:17:59.307893900Z"
        },
        "id": "70e0dafc455c5fdd"
      },
      "id": "70e0dafc455c5fdd"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "source": [
        "def is_sample_biased(sample,unpriv_cols,bias_dict,bias_threshold):\n",
        "    biased_cols = 0\n",
        "    for col in unpriv_cols:\n",
        "        if sample[col] == 1 and not bias_dict[col][\"privilege in one\"] and bias_dict[col][\"majority in 1\"] == sample[\"pred\"]:\n",
        "            biased_cols += 1\n",
        "        elif sample[col] == 0 and not bias_dict[col][\"privilege in zero\"] and bias_dict[col][\"majority in 0\"] == sample[\"pred\"]:\n",
        "            biased_cols += 1\n",
        "    if biased_cols >= bias_threshold:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.579365600Z",
          "start_time": "2023-10-17T14:17:59.333896500Z"
        },
        "id": "1fd35dc66c8c5c3b"
      },
      "id": "1fd35dc66c8c5c3b"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.579931100Z",
          "start_time": "2023-10-17T14:17:59.357900400Z"
        },
        "id": "1325a220f35c86b"
      },
      "id": "1325a220f35c86b"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "source": [
        "def identify_bias_samples(test, bias_dict, biased_cols):\n",
        "    list_of_biased_samples = []\n",
        "\n",
        "    for index, sample in test.iterrows():\n",
        "        if is_sample_biased(sample, biased_cols, bias_dict):\n",
        "            list_of_biased_samples.append(index)\n",
        "    return list_of_biased_samples\n",
        ""
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.580902100Z",
          "start_time": "2023-10-17T14:17:59.383910400Z"
        },
        "id": "df121bcbb01114e8"
      },
      "id": "df121bcbb01114e8"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "source": [
        "def calc_test_bias_no_bias(test, model,target,bias_dict,bias_threshold):\n",
        "    biased_cols =[]\n",
        "\n",
        "    for feature in bias_dict.keys():\n",
        "        if not bias_dict[feature][\"privilege in one\"] or not bias_dict[feature][\"privilege in zero\"]:\n",
        "            biased_cols.append(feature)\n",
        "    test[\"pred\"] = model.predict(test.drop(target, axis=1))\n",
        "    original_accuracy = accuracy_score(test[target], test[\"pred\"])\n",
        "    print(f\"original accuracy: {original_accuracy}\")\n",
        "    test[\"is_bias\"] = test.apply(lambda row: is_sample_biased(row, biased_cols,bias_dict,bias_threshold), axis=1)\n",
        "    test_sample_with_bias = test[test[\"is_bias\"]==True]\n",
        "    test_sample_without_bias = test[test[\"is_bias\"]==False]\n",
        "    accuracy_with_bias = accuracy_score(test_sample_with_bias[target], test_sample_with_bias[\"pred\"])\n",
        "\n",
        "    # Calculate accuracy for samples without bias\n",
        "    accuracy_without_bias = accuracy_score(test_sample_without_bias[target], test_sample_without_bias[\"pred\"])\n",
        "    print('number of samples: ', len(test))\n",
        "    print('number of samples with bias: ', len(test_sample_with_bias))\n",
        "    print('number of samples without bias: ', len(test_sample_without_bias))\n",
        "    print('percentage of samples with bias: ', len(test_sample_with_bias)/len(test))\n",
        "    return accuracy_with_bias, accuracy_without_bias\n",
        ""
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.580902100Z",
          "start_time": "2023-10-17T14:17:59.427884900Z"
        },
        "id": "9f7cc610373382e1"
      },
      "id": "9f7cc610373382e1"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:17:59.583893300Z",
          "start_time": "2023-10-17T14:17:59.445881300Z"
        },
        "id": "ee9670844ab2615e"
      },
      "id": "ee9670844ab2615e"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.659919028340081\n",
            "original accuracy: 0.6866396761133603\n",
            "number of samples:  1235\n",
            "number of samples with bias:  831\n",
            "number of samples without bias:  404\n",
            "percentage of samples with bias:  0.6728744939271255\n",
            "compass accuracy with bias: 0.6787003610108303\n",
            "compass accuracy without bias: 0.7029702970297029\n"
          ]
        }
      ],
      "source": [
        "compass_train, compass_test = train_test_split(compass, test_size=0.2, random_state=42,stratify=compass[compass_target])\n",
        "compass_bias_dict = bias_in_dataset(compass_train, compass_target, compass_one_hot_col)\n",
        "import_csv_summary(compass_bias_dict, \"compass\")\n",
        "compass_infer_model = RandomForestClassifier(n_estimators=10, max_depth=5,random_state=42)\n",
        "compass_infer_model.fit(compass_train.drop(columns=[compass_target]), compass_train[compass_target])\n",
        "compass_accuracy_with_bias, compass_accuracy_without_bias = calc_test_bias_no_bias(compass_test, compass_infer_model, compass_target, compass_bias_dict, sample_is_bias_threshold)\n",
        "print(f\"compass accuracy with bias: {compass_accuracy_with_bias}\")\n",
        "print(f\"compass accuracy without bias: {compass_accuracy_without_bias}\")\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-17T14:18:15.780973400Z",
          "start_time": "2023-10-17T14:17:59.470895300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c95209a3cc5493f5",
        "outputId": "278319ff-ed8d-4ea6-9307-680f51e402a4"
      },
      "id": "c95209a3cc5493f5"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8668611793611793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original accuracy: 0.8238906801781053\n",
            "number of samples:  6513\n",
            "number of samples with bias:  5470\n",
            "number of samples without bias:  1043\n",
            "percentage of samples with bias:  0.8398587440503608\n",
            "adult accuracy with bias: 0.8460694698354662\n",
            "adult accuracy without bias: 0.7075743048897412\n"
          ]
        }
      ],
      "source": [
        "adult_train, adult_test = train_test_split(adult, test_size=0.2, random_state=42,stratify=adult[adult_target])\n",
        "adult_bias_dict = bias_in_dataset(adult_train, adult_target, adult_one_hot_col)\n",
        "import_csv_summary(adult_bias_dict, \"adult\")\n",
        "adult_infer_model = RandomForestClassifier(n_estimators=10, max_depth=5,random_state=42)\n",
        "adult_infer_model.fit(adult_train.drop(columns=[adult_target]), adult_train[adult_target])\n",
        "adult_accuracy_with_bias, adult_accuracy_without_bias = calc_test_bias_no_bias(adult_test, adult_infer_model, adult_target, adult_bias_dict,4)\n",
        "print(f\"adult accuracy with bias: {adult_accuracy_with_bias}\")\n",
        "print(f\"adult accuracy without bias: {adult_accuracy_without_bias}\")"
      ],
      "metadata": {
        "is_executing": true,
        "ExecuteTime": {
          "start_time": "2023-10-17T14:18:15.785961200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c23ea40e1a135a45",
        "outputId": "b07de160-9562-405b-d5a4-4617095819d4"
      },
      "id": "c23ea40e1a135a45"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8995192307692308\n",
            "original accuracy: 0.8966346153846154\n",
            "number of samples:  4160\n",
            "number of samples with bias:  0\n",
            "number of samples without bias:  4160\n",
            "percentage of samples with bias:  0.0\n",
            "law accuracy with bias: nan\n",
            "law accuracy without bias: 0.8966346153846154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Mean of empty slice.\n",
            "invalid value encountered in double_scalars\n"
          ]
        }
      ],
      "source": [
        "law_train, law_test = train_test_split(law, test_size=0.20, random_state=42,stratify=law[law_target])\n",
        "law_bias_dict = bias_in_dataset(law_train, law_target, law_one_hot_col)\n",
        "import_csv_summary(law_bias_dict, \"law\")\n",
        "law_infer_model = RandomForestClassifier(n_estimators=10, max_depth=5,random_state=42)\n",
        "law_infer_model.fit(law_train.drop(columns=[law_target]), law_train[law_target])\n",
        "law_accuracy_with_bias, law_accuracy_without_bias = calc_test_bias_no_bias(law_test, law_infer_model, law_target, law_bias_dict, sample_is_bias_threshold)\n",
        "print(f\"law accuracy with bias: {law_accuracy_with_bias}\")\n",
        "print(f\"law accuracy without bias: {law_accuracy_without_bias}\")"
      ],
      "metadata": {
        "is_executing": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96af15bca581fb",
        "outputId": "1294cac7-8a2c-4dd3-fc5c-2919ed9082f7"
      },
      "id": "96af15bca581fb"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.762878705020234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n",
            "invalid value encountered in long_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original accuracy: 0.7579569069233293\n",
            "number of samples:  9143\n",
            "number of samples with bias:  48\n",
            "number of samples without bias:  9095\n",
            "percentage of samples with bias:  0.005249917970031718\n",
            "diabetes accuracy with bias: 0.7708333333333334\n",
            "diabetes accuracy without bias: 0.7578889499725123\n"
          ]
        }
      ],
      "source": [
        "diabetes_train,diavitic_test = train_test_split(diabetes, test_size=0.2, random_state=42, stratify=diabetes[diabetes_target])\n",
        "diabetes_bias_dict = bias_in_dataset(diabetes_train, diabetes_target, diabetes_one_hot_col)\n",
        "import_csv_summary(diabetes_bias_dict, \"diabetes\")\n",
        "diabetes_infer_model = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=42)\n",
        "diabetes_infer_model.fit(diabetes_train.drop(columns=[diabetes_target]), diabetes_train[diabetes_target])\n",
        "diabetes_accuracy_with_bias, diabetes_accuracy_without_bias = calc_test_bias_no_bias(diavitic_test, diabetes_infer_model, diabetes_target, diabetes_bias_dict, sample_is_bias_threshold)\n",
        "print(f\"diabetes accuracy with bias: {diabetes_accuracy_with_bias}\")\n",
        "print(f\"diabetes accuracy without bias: {diabetes_accuracy_without_bias}\")\n"
      ],
      "metadata": {
        "is_executing": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bec9dfc750ce31ef",
        "outputId": "3cc0d4d8-3050-4a51-b4d4-f7ee7117e892"
      },
      "id": "bec9dfc750ce31ef"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [],
      "source": [],
      "metadata": {
        "is_executing": true,
        "id": "19902ae7da0e33a4"
      },
      "id": "19902ae7da0e33a4"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hI-FEomDdW4u"
      },
      "id": "hI-FEomDdW4u",
      "execution_count": 41,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}